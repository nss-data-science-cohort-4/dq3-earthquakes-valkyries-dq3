{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TNEG Geospatial Visualizations\n",
    "\n",
    "This notebook contains a base map with county-level breakdown for the state of TN.  \n",
    "\n",
    "The following dataframes have been joined to the map:  \n",
    "* ``earthquakes`` Deadly earthquakes since 1900 (from Wikipedia)\n",
    "* ``usgs`` Earthquakes in and around TN since 1900 (from the USGS API)\n",
    "* ``TN_demo`` TN county-level demographic information including total population, % of children (under 18), % of people living in rural or isolated settings, % of people of color, % of people with disabilities, and % of senior citizens (from the TN Arts Commission, derived from the 2010 US census)\n",
    "* ``TN_housing_units_by_county`` TN county-level aggregates of total population and number of housing units (from the 2010 census)\n",
    "* ``acs_data``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import ipywidgets as widgets\n",
    "#from bs4 import BeautifulSoup as bs\n",
    "from IPython.core.display import HTML\n",
    "#import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pylab as plt\n",
    "import json\n",
    "from bokeh.io import output_file, show, output_notebook, export_png\n",
    "from bokeh.models import ColumnDataSource, GeoJSONDataSource, LinearColorMapper, ColorBar\n",
    "from bokeh.models.widgets import DataTable\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.palettes import brewer\n",
    "import panel as pn\n",
    "import panel.widgets as pnw\n",
    "#import seaborn as sns\n",
    "from io import StringIO\n",
    "from shapely.geometry import Point\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "from folium.plugins import FastMarkerCluster\n",
    "from cartopy.io import shapereader\n",
    "%matplotlib inline\n",
    "# import io\n",
    "# import scipy.stats as stats\n",
    "# import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display settings\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a base map for the state of TN, broken down by county."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a folium map, but probably not the best idea to subsequently join all of the other data\n",
    "# tn_map = folium.Map(location=[36,-86], zoom_start = 7)\n",
    "# tn_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a base map by importing the base shape file for TN census map\n",
    "# Annoyingly, this is broken down by census division, not by county\n",
    "# tn_census_map = gpd.read_file('../data/2018-TN-basemap/tl_2016_47_cousub.shp')\n",
    "# tn_census_map.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see if COUNTYFP |is the right level to aggregate at to get county-level geometries\n",
    "# tn_census_map['COUNTYFP'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt to aggregate geometries by county - and not succeed\n",
    "# tn_census_map.groupby('COUNTYFP')['geometry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask Michael, get this county-level base map shapefile instead\n",
    "tn_county_map = gpd.read_file('../data/TN-county-basemap/tncounty.shp')\n",
    "# See what the map looks like\n",
    "tn_county_map.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the base map dataframe\n",
    "tn_county_map.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to make sure nothing is missing\n",
    "tn_county_map.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the projection type\n",
    "tn_county_map.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the projection type\n",
    "tn_county_map = tn_county_map.to_crs('EPSG:4326')\n",
    "print(tn_county_map.crs)\n",
    "# Clean up some of the columns we don't need\n",
    "tn_county_map = tn_county_map.drop(['OBJECTID', 'KEY', 'SHAPE_LEN'], axis = 1)\n",
    "# Reformat column headers\n",
    "tn_county_map.columns = ['county', 'shape_area', 'geometry']\n",
    "# Set the county names to lower case\n",
    "tn_county_map['county'] = tn_county_map['county'].str.lower()\n",
    "# Make sure the base map dataset is good to go\n",
    "tn_county_map.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the deadly earthquakes since 1900 wikitable and turn it into a Geo DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earthquakes = pd.read_csv('../data/earthquakes_wikitable.csv')\n",
    "earthquakes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data types\n",
    "earthquakes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the origin_utc column to a datetime\n",
    "earthquakes['origin_utc'] = pd.to_datetime(earthquakes['origin_utc'])\n",
    "# Create \n",
    "earthquakes['magnitude_type'] = earthquakes['magnitude'].str.extract(r'.*?(\\w+)$')\n",
    "# Clean up the lat/long columns\n",
    "earthquakes['latitude'] = earthquakes['lat'].str.replace('?','')\n",
    "earthquakes['longitude'] = earthquakes['long'].str.replace('?','')\n",
    "# Turn the lat/long into floats\n",
    "earthquakes['latitude'] = pd.to_numeric(earthquakes['latitude'], errors = 'raise')\n",
    "earthquakes['longitude'] = pd.to_numeric(earthquakes['longitude'], errors = 'raise')\n",
    "# Remove excess columns\n",
    "earthquakes = earthquakes.drop(['date_ymd', 'time', 'lat', 'long', 'magnitude', 'pde_shaking_deaths', 'pde_total_deaths', 'utsu_total_deaths', 'em_dat_total_deaths', 'other_source_deaths', 'other_source_deaths_new', 'osd1', 'osd2', 'osd3'], axis = 1)\n",
    "# Reorder columns\n",
    "earthquakes = earthquakes[['origin_utc', 'country', 'latitude', 'longitude', 'depth_km', 'magnitude_num', 'magnitude_type', 'secondary_effects', 'max_deaths']]\n",
    "# Make sure the data types are correct\n",
    "earthquakes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column named 'geometry' which combines the latitude and longitude\n",
    "earthquakes['geometry'] = earthquakes.apply(lambda x: Point((float(x.longitude),\n",
    "                                                            float(x.latitude))),\n",
    "                                           axis = 1)\n",
    "earthquakes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the Wikipedia Deadly Earthquakes since 1900 table into a Geo Data Frame\n",
    "earthquakes_geo = gpd.GeoDataFrame(earthquakes,\n",
    "                                   crs = tn_county_map.crs,\n",
    "                                   geometry = earthquakes['geometry'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Wikipedia deadly earthquakes since 1900 table is now ready for a spatial join."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, pull in the USGS data for earthquakes in TN and turn it into a Geo DataFrame.  \n",
    "\n",
    "Use the coordinates in this [gist](https://gist.github.com/jakebathman/719e8416191ba14bb6e700fc2d5fccc5) to only get earthquakes from near TN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the query URL\n",
    "url = 'https://earthquake.usgs.gov/fdsnws/event/1/query?format=csv&starttime=1900-01-01&endtime=2020-10-22&minlatitude=34.9884&maxlatitude=36.6871&minlongitude=-90.3131&maxlongitude=-81.6518'\n",
    "# Assign the response to a variable\n",
    "r = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read in the text of the response into a dataframe called usgs\n",
    "usgs = pd.read_csv(StringIO(r.text))\n",
    "# See what gets returned\n",
    "usgs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure all of the fields are the proper data types\n",
    "usgs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove excess columns\n",
    "usgs = usgs.drop(['nst', 'gap', 'dmin', 'rms', 'net', 'id', 'updated', 'horizontalError', 'depthError', 'magError', 'magNst', 'status', 'status', 'locationSource', 'magSource'], axis = 1)\n",
    "usgs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a geometry column\n",
    "usgs['geometry'] = usgs.apply(lambda x: Point((float(x.longitude),\n",
    "                                            float(x.latitude))),\n",
    "                              axis = 1)\n",
    "# Make sure it worked\n",
    "usgs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Subset to earthquakes that have happened within TN only, based on the place name\n",
    "# Not actually necessary if we're going to plot points based on lat/long\n",
    "# usgs_tn = usgs[usgs['place'].str.contains('(Tennessee)')]\n",
    "# usgs_tn.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the USGS dataframe into a Geo DataFrame\n",
    "usgs_geo = gpd.GeoDataFrame(usgs,\n",
    "                            crs = tn_county_map.crs,\n",
    "                            geometry = usgs['geometry'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The usgs dataframe is now ready for a spatial join."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the TN demographics data by county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn_demo = pd.read_csv('../data/TN-county-demographics-2010.csv')\n",
    "# Check the top of the tn_demo dataframe\n",
    "tn_demo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower case the county to avoid merge errors\n",
    "tn_demo['County'] = tn_demo['County'].str.lower()\n",
    "# Rename columns\n",
    "tn_demo.columns = ['county', 'total_pop', 'pct_children_under_18', 'pct_people_living_in_rural_areas', 'pct_people_of_color', 'pct_people_with_disabilities', 'pct_senior_citizens']\n",
    "tn_demo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove non-numeric characters from the columns\n",
    "tn_demo[['pct_children_under_18', 'pct_people_living_in_rural_areas', 'pct_people_of_color', 'pct_people_with_disabilities', 'pct_senior_citizens']] = tn_demo[['pct_children_under_18', 'pct_people_living_in_rural_areas', 'pct_people_of_color', 'pct_people_with_disabilities', 'pct_senior_citizens']].apply(lambda x: x.str.replace('%',''))\n",
    "tn_demo.total_pop = tn_demo.total_pop.str.replace(',','')\n",
    "tn_demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn_demo[['total_pop', 'pct_children_under_18', 'pct_people_living_in_rural_areas', 'pct_people_of_color', 'pct_people_with_disabilities', 'pct_senior_citizens']] = tn_demo[['total_pop', 'pct_children_under_18', 'pct_people_living_in_rural_areas', 'pct_people_of_color', 'pct_people_with_disabilities', 'pct_senior_citizens']].apply(pd.to_numeric, errors = 'raise')\n",
    "tn_demo.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TN demographics dataframe is now ready for a non-spatial join."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in and clean up the census housing units by county for TN data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only read in the relevant lines of the csv\n",
    "tn_housing = pd.read_csv('../data/us_census_tn_housing_units_by_county_2010-2019.csv')[2:99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the first row as the column headers\n",
    "tn_housing.columns = tn_housing.iloc[0]\n",
    "# Remove the excess lines from the dataframe\n",
    "tn_housing = tn_housing[2:99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index\n",
    "tn_housing = tn_housing.reset_index(drop = True)\n",
    "tn_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the excess columns\n",
    "tn_housing = tn_housing.drop(['Census', 'Estimates Base', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018'], axis = 1)\n",
    "# Rename the columns\n",
    "tn_housing.columns = ['county', 'total_housing_units_2019']\n",
    "# Clean up and standardize the county names\n",
    "tn_housing['county'] = tn_housing['county'].str.extract(r'\\.(.*) County, Tennessee')\n",
    "tn_housing['county'] = tn_housing['county'].str.lower()\n",
    "tn_housing['total_housing_units_2019'] = tn_housing['total_housing_units_2019'].str.replace(',','')\n",
    "tn_housing['total_housing_units_2019'] = pd.to_numeric(tn_housing['total_housing_units_2019'], errors = 'raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tn_housing.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TN housing units dataset is now ready to join."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the ACS dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs = pd.read_csv('../data/acs_5yr_subset_clean.csv')\n",
    "acs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ACS data has already been cleaned and is ready for a non-spatial join."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the CDC Social Vulnerability Index dataframe\n",
    "\n",
    "From [here](https://www.atsdr.cdc.gov/placeandhealth/svi/data_documentation_download.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only read in the Social Vulnerability Index scores for the counties in TN\n",
    "svi = pd.read_csv('../data/TN-vulnerability-scores.csv', usecols=['COUNTY','AREA_SQMI','RPL_THEME1','RPL_THEME2','RPL_THEME3','RPL_THEME4','RPL_THEMES'])\n",
    "svi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svi.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the columns\n",
    "svi.columns = ['county', 'area_m2', 'socioeconomic', 'household_comp_and_disability', 'minority_status_and_language', 'housing_type_and_transportation', 'total_vulnerability']\n",
    "svi.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the county to lowercase to facilitate joins\n",
    "svi['county'] = svi['county'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the dataset by the county, then reset the index\n",
    "svi = svi.sort_values('county').reset_index(drop=True)\n",
    "svi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The svi dataset is ready to join."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge the non-spatial dataframes together  \n",
    "\n",
    "Merge on the county level to build the framework for mapping the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the demographics and housing data into one dataframe\n",
    "tn_housing_demo = tn_demo.merge(tn_housing, how = 'outer', on = 'county')\n",
    "tn_housing_demo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tn_housing_demo_acs = tn_housing_demo.merge(acs, how = 'outer', on = 'county')\n",
    "tn_housing_demo_acs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tn_housing_demo_acs_svi = tn_housing_demo_acs.merge(svi, how = 'outer', on = 'county')\n",
    "tn_housing_demo_acs_svi.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the final dataframe for ease of use\n",
    "tn_data = tn_housing_demo_acs_svi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge the non-spatial aggregate dataframe to the base map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join in the demographic data to the TN base map\n",
    "tn_data_map = tn_county_map.merge(tn_data, on = 'county')\n",
    "# Check to make sure it is a full join\n",
    "tn_data_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check to make sure nothing got dropped along the way\n",
    "tn_data_map.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start exploring the data visually\n",
    "ax = tn_data_map.plot(column='total_vulnerability', cmap =    \n",
    "                                'YlGnBu', figsize=(15,9),   \n",
    "                                 legend = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a widget\n",
    "@widgets.interact(\n",
    "    column = ['total_pop', 'pct_children_under_18', 'pct_people_living_in_rural_areas'])\n",
    "\n",
    "def throw_some_shade():\n",
    "    \"\"\"\n",
    "    Change the choropleth based on the column value\n",
    "    \"\"\"\n",
    "    ax = tn_data_map.plot(column='total_pop', cmap =    \n",
    "                                'YlGnBu', figsize=(15,9),   \n",
    "                                 legend = True)\n",
    "    ax.plot(column = 'total_pop')\n",
    "#widgets.interact(throw_some_shade, col=['total_pop', 'pct_children_under_18', 'pct_people_living_in_rural_areas']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add of the USGS earthquakes since 1900 to the data-enriched TN base map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the USGS data to the TN basemap\n",
    "tn_earthquakes = gpd.sjoin(usgs_geo, tn_data_map, op = 'within')\n",
    "tn_earthquakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Since 1900, how many earthquakes per county?\n",
    "tn_earthquakes['county'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map the earthquakes, color-coded by magnitute\n",
    "ax = tn_county_map.plot(figsize = (8, 10), color = 'beige')\n",
    "tn_earthquakes.plot( ax = ax, column = 'mag');\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map the earthquakes, color-coded by county\n",
    "ax = tn_county_map.plot(figsize = (8, 10), color = 'beige')\n",
    "tn_earthquakes.plot( ax = ax, column = 'county');\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn_earthquakes['county'].value_counts().hist(bins = 35);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tn_earthquakes['mag'].hist(bins = 35);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn_earthquakes['depth'].hist(bins = 35);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
